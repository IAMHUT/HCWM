# 🚀 Hybrid Causal World Model



**强化学习算法性能对比实验**  
*完整 RSSM + 想象轨迹训练版本*

---

## 🎯 项目简介

本项目实现并对比了多种主流强化学习算法在 CartPole-v1 环境上的性能表现。核心亮点是基于 **RSSM (Recurrent State Space Model)** 的世界模型与想象轨迹训练机制，实现了更高效的样本利用率和更快的收敛速度。

---

## ✨ 功能特性

### 核心算法

- ✅ **Enhanced Hybrid Regret PPO** - 集成 RSSM 世界模型的增强型 PPO
  - 完整的 RSSM 组件
  - 想象轨迹生成与训练
  - 双策略网络架构（真实环境 + 想象环境）
  - 基于后悔值的优先级经验回放
  
- ✅ **Vanilla PPO** - 标准 PPO 实现
- ✅ **REINFORCE** - 经典策略梯度算法
- ✅ **A2C** - Advantage Actor-Critic

### 技术亮点

| 特性             | 描述                                   |
| ---------------- | -------------------------------------- |
| 🌍 **世界模型**   | RSSM 架构，支持状态预测和奖励预测      |
| 💭 **想象训练**   | 在学习的世界模型中生成轨迹进行额外训练 |
| 📈 **优先级回放** | 基于 TD-error 和后悔值的经验优先级     |
| 🎯 **后悔值计算** | 评估动作选择的机会成本                 |
| 📊 **自动可视化** | 学习曲线、收敛速度、损失变化等         |
| 💾 **数据导出**   | Excel/CSV 格式，便于后续分析           |



.
